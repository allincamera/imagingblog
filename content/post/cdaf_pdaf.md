+++
categories = ["hardware", "software", "system"]
date = "2016-04-07T13:32:07+08:00"
tags = ["sensor", "isp", "lens", "algorithm"]
title = "反差对焦 vs. 相差对焦"

+++

## 反差式对焦评价函数的频率特性考虑

当前手机成像系统中普遍使用反差式对焦系统，也就是计算当前图像的锐度，依照图像锐度与镜头位置的关系，寻找最锐度最高的镜头位置作为合焦位置的方法。在搜索策略上各厂商基本相似，在锐度提取也就是清晰度的计算上，应该根据光学特性的不同做差异化设计。

基于芯片硬件设计的方便性考虑，大部分的锐度评价函数都设计为一个m x n算子，记作P，算子的填充决定其特性：一般是高通，或者是带通滤波器。如果图像记作G，那么图像的锐度S可以表示为：
S = P * G  P 对 G 做卷积。

### 高通与带通滤波器的优缺点

高通滤波器对高频成分很敏感，当成像系统离焦不远时，图像高频成分很容易被提取出来，随着镜头的移动，计算出锐度的差异很明显。但是当图像离焦很远时，比如对焦的物体消失，背景物体又在远处，高通滤波器对图像的响应就不明显，这样镜头移动计算出的锐度变化就不明显，造成搜索失败。

如下图

![Band Pass Filter](https://raw.githubusercontent.com/allincamera/imgur/master/cdaf_pdaf/bandpass_filter.gif)

当锐度值在曲线两侧，无论镜头如何移动，变化都非常不明显，这样搜索算法就很难工作，这个评价函数就是不合适的。为了解决这个问题，就需要在设计滤波器P的时候，让低频成分多通过一些。

![Low Pass Filter](https://raw.githubusercontent.com/allincamera/imgur/master/cdaf_pdaf/P1P2.gif)

蓝色的曲线是滤波器P1的频率响应，绿色的曲线是滤波器P2的频率响应，相比可见，绿色曲线可以让更多低频成分通过。
	
选择一个滤波器后，需要根据实际图像进行计算仿真，画出这个滤波器对不同离焦程度图像卷积所产生的锐度值

``` matlab
	  kern = [-1 -2 -3 -5 -8;8 5 3 2 1];%c    
	%  kern = [-1  0  1; -2 0  2; -1  0  1];%r
	%     kern = [ -1 -1 -1;-1 0 1;1 1 1];%g
	%     kern = [ -1 -1 -1;-1 8 -1;-1 -1 -1];%b
	%    kern = [ 7 5 -1 0 -1 ;1 0 -5 1 -7]; %m
	     kern = [ 6 0 6 0 0 ;0 -12 0 0 0];%k
	%    kern = [-5 -4 0 4 5;-8 -10 0 10 8;10 -20 0 20 0;-8 -10 0 10 8;-5 -4 0 4 5]%y
```

![Filter Comparison](https://raw.githubusercontent.com/allincamera/imgur/master/cdaf_pdaf/filters_comparison.gif)

上图就是上面的各个滤波器的仿真结果，横坐标是离焦程度，从0到25，离焦程度逐步变大。纵坐标是计算出的锐度值，1表示最大。通过这个曲线，可以看出对不同离焦程度图像滤波器的响应，依据响应曲线的特点进行选择。

## 片上相差式自动对焦（on chip phase detection autofocus）原理

相差式自动对焦与反差式自动对焦是现在手机成像系统中两大主要自动对焦方式。相比反差式自动对焦，相差式自动对焦只需要一次计算，就可以完成对焦。
	
当前比较流行的是片上相差自动对焦, 在生产sensor的时候，把某些用于相位检测像素遮住左边一半或者右边一半，如下图

![Focus Pixels Array](https://raw.githubusercontent.com/allincamera/imgur/master/cdaf_pdaf/focus_pixel_array.png)

上图只是示意图，各个厂商的半掩模的工艺各有不同，在对IR filter或者microlens的处理上也不相同，但是基本的原理都是让图像形成左右两幅类似人眼的不同光学通路的图像。

这样左右侧的相位检测像素就会产生这样的图像：

![Phase diff in focus pixels](https://raw.githubusercontent.com/allincamera/imgur/master/cdaf_pdaf/focus_pixel_sequence.png)

数字化以后就产生了两个序列。

图像聚焦时，两个序列做互相关运算产生的数值变小，图像离焦时，两个序列做互相关产生的数值变大。如果对相机模组进行校准----针对一个固定图形的高频图像移动镜头，计算互相关运算产生的数值，记录下来成为基准表。在相机工作时，根据实时计算的互相关数值，通过查找基准表，就可以知道当前的离焦程度，从而找到移动方向和移动到什么位置。

数学推导简化起来就是如下公式：

左右两个图像产生的数列做互相关，得到一个对焦函数，可以把相差与镜头的偏移量变成一一对应关系。

![PDAF func](https://raw.githubusercontent.com/allincamera/imgur/master/cdaf_pdaf/pdaf_func.png)

实际工程上计算得到的结果就如下边图中所示，5x5窗口，每个窗口里边的统计数据包括两个部分，高16位是相位差，低16位是置信度。在平坦区域，置信度低，在细节丰富的区域，置信度高（300）。

![PDAF output](https://raw.githubusercontent.com/allincamera/imgur/master/cdaf_pdaf/pdaf_output.png)

通过固定图卡校准可以得到lens 偏移量和相差的对应数组：

> PDAF_Calibration[][2] = {{1,1},{2,3},{3,5},{4,7},{5,9},{6,10},{7,11},{8,12},{9,13},{10,14},{11,15},{12,16},{13,17},{14,18},{15,19},{16,20}, {20,30},{24,40},{28,47},{32,50},{40,70},{48,80},{56,96},{64,110},{80,138},{96,160},{112,180},{128,210}};
	
所以当AF开始工作时，通过实时计算得到相差值，eg： 210， 那么对应移动lens的距离，就是128,如果得到相差值是-210，就移动lens向反方向128个单位。
